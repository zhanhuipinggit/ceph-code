# Ceph-Code

## 项目概述

`ceph-code` 是一个实现 Ceph 存储系统核心算法及 CRUSH 映射算法的开源库。Ceph 是一个分布式存储系统，提供高可用、可扩展的存储解决方案。该项目的目的是帮助开发者理解 Ceph 的核心机制，特别是如何通过 CRUSH 算法来实现数据的分布与高效存储。

### 主要内容

- **CRUSH 算法**：负责将存储对象映射到 Ceph 集群中的存储节点。
- **Ceph 核心功能**：包括数据的存储、复制、高可用性、负载均衡等。
- **Ceph 存储引擎的实现**：模拟并实现 Ceph 内部的一些关键功能，如 OSD、MON、MDS 等。

## CRUSH 算法简介

### 什么是 CRUSH 算法？

CRUSH（Controlled Replication Under Scalable Hashing）算法是 Ceph 存储系统中的核心算法，负责决定如何将数据映射到存储集群中的不同节点上。CRUSH 使 Ceph 能够在没有集中式目录服务的情况下，高效地管理分布式数据的存储。

#### CRUSH 算法的核心概念：
1. **集群拓扑**：Ceph 的 CRUSH 算法基于集群的拓扑结构来决定数据存放的位置。集群的拓扑结构通常由多个设备、节点、池、存储设备等层次组成。
2. **数据分布**：通过 CRUSH 算法，将数据以高效的方式分布在不同的存储节点上，确保数据均匀分布并且支持快速的数据访问。
3. **副本管理**：CRUSH 不仅负责数据的映射，还涉及到副本的管理，确保数据的可靠性和高可用性。
4. **无中心化**：CRUSH 不依赖于集中式目录服务器（如传统的存储系统），而是通过哈希算法根据集群拓扑动态计算数据位置。

### CRUSH 算法的优点：
- **去中心化**：CRUSH 不依赖于中心化的元数据服务器，避免了单点故障的问题。
- **高效性**：通过哈希算法和拓扑结构，可以高效地将数据映射到多个节点，支持高并发读写。
- **扩展性**：CRUSH 支持动态扩展，随着集群规模的扩大，算法可以自动调整数据的分布。

## Ceph 核心内容简介

Ceph 是一个开源的分布式存储系统，提供对象存储、块存储和文件存储等多种存储服务，具有以下特点：

1. **高可用性**：通过 CRUSH 算法和副本机制，Ceph 能够保证数据的可靠性和高可用性。
2. **自动化扩展**：Ceph 可以在运行时自动增加存储节点，而不需要人工干预。
3. **强一致性**：Ceph 的一致性模型通过分布式协议实现，确保在节点故障或网络分区的情况下，数据不会丢失。
4. **统一的存储平台**：Ceph 提供对象存储（RADOS）、块存储（RBD）、文件系统（CephFS）等多种存储接口，满足不同应用场景的需求。

### Ceph 的核心组件：
1. **OSD（Object Storage Daemon）**：负责数据存储和副本管理。每个 OSD 处理一部分数据，支持数据的读写和复制。
2. **MON（Monitor）**：监控集群状态，维护集群的健康信息，确保数据一致性。
3. **MDS（Metadata Server）**：为 CephFS 提供元数据管理，处理文件系统的目录、文件和权限信息。
4. **CRUSH**：决定数据如何存储和复制的核心算法。

## `ceph-code` 库简介

`ceph-code` 库实现了 Ceph 的一些核心算法和数据结构，帮助开发者理解和使用 Ceph 的内部工作原理。该库包括以下内容：

### 核心功能：
1. **CRUSH 算法实现**：通过模拟 Ceph 的 CRUSH 映射机制，实现如何将数据映射到集群中的节点。
2. **集群拓扑管理**：模拟集群拓扑，支持添加节点、设备和池，并支持数据映射。
3. **数据分布与负载均衡**：基于集群拓扑和 CRUSH 算法实现数据的分布和负载均衡。
4. **模拟 Ceph OSD 操作**：实现了 Ceph 存储节点的基本操作，如数据存储、读取、复制等。
5. **简单的存储引擎**：模拟 Ceph 存储引擎的基本工作机制，包括对象存储和文件存储接口。

#### 因为是演示，所有很多都是慢慢完善以及解构ceph，并非可以直接作为工程来应用，主要目的是学习

